{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73abdqyU_7Mp",
        "outputId": "5ca1481f-1404-4919-c2d5-e9ff595862f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "import numpy as np\n",
        "import os\n",
        "sys.path.append(os.path.abspath('../data'))\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import PackedSequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "991pXTkGBbsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import re\n",
        "\n",
        "def tokenize(expression):\n",
        "    \"\"\"Convert expression string to tokens, preserving operators.\"\"\"\n",
        "    # Replace parentheses with spaces\n",
        "    expr = expression.replace('(', ' ').replace(')', ' ')\n",
        "\n",
        "    # Add spaces around brackets that aren't part of operators\n",
        "    expr = re.sub(r'\\[(?!(MIN|MAX|MED|SM))', ' [ ', expr)\n",
        "    expr = expr.replace(']', ' ] ')\n",
        "\n",
        "    # Split and filter empty strings\n",
        "    return [token for token in expr.split() if token]\n",
        "\n",
        "class ListOpsDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            X: Array of source expressions\n",
        "            y: Array of target values\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        # Create vocabulary from operators and digits\n",
        "        self.vocab = {\n",
        "            'PAD': 0,  # Padding token\n",
        "            '[MIN': 1,\n",
        "            '[MAX': 2,\n",
        "            '[MED': 3,\n",
        "            '[SM': 4,\n",
        "            ']': 5,\n",
        "            '(': 6,\n",
        "            ')': 7\n",
        "        }\n",
        "        # Add digits 0-9\n",
        "        for i in range(10):\n",
        "            self.vocab[str(i)] = i + 8\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def tokenize(self, expr):\n",
        "        \"\"\"Convert expression to token IDs.\"\"\"\n",
        "        tokens = tokenize(expr)  # Using our previous tokenize function\n",
        "        return [self.vocab.get(token, 0) for token in tokens]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        expr = self.X[idx]\n",
        "        target = self.y[idx]\n",
        "\n",
        "        # Convert to token IDs without padding or truncating\n",
        "        token_ids = self.tokenize(expr)\n",
        "\n",
        "        return {\n",
        "            'input_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "            'target': torch.tensor(target, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "dgBVBfXxBfgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "__aoAlH2Bfkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t6Xzt7x0BfoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the data directory and file paths\n",
        "data_dir = '/content/drive/MyDrive/LongListOps/data/output_dir'\n",
        "train_file = os.path.join(data_dir, 'basic_train.tsv')\n",
        "val_file = os.path.join(data_dir, 'basic_val.tsv')\n",
        "test_file = os.path.join(data_dir, 'basic_test.tsv')\n",
        "\n",
        "def load_listops_data(file_path, max_rows=None):\n",
        "    \"\"\"\n",
        "    Load ListOps data from TSV file.\n",
        "\n",
        "    Args:\n",
        "        file_path: Path to the TSV file\n",
        "        max_rows: Maximum number of rows to load (for testing)\n",
        "\n",
        "    Returns:\n",
        "        sources: Array of source expressions\n",
        "        targets: Array of target values (0-9)\n",
        "    \"\"\"\n",
        "    sources = []\n",
        "    targets = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        next(f)  # Skip header (Source, Target)\n",
        "        for i, line in enumerate(f):\n",
        "            if max_rows and i >= max_rows:\n",
        "                break\n",
        "            if not line.strip():  # Skip empty lines\n",
        "                continue\n",
        "            parts = line.strip().split('\\t')\n",
        "            if len(parts) != 2:\n",
        "                continue  # Skip lines that don't have exactly two columns\n",
        "            source, target = parts\n",
        "            sources.append(source)\n",
        "            targets.append(int(target))  # Target is always 0-9\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    source_array = np.array(sources, dtype=object)  # Keep expressions as strings\n",
        "    target_array = np.array(targets, dtype=np.int32)  # Targets are integers\n",
        "\n",
        "    return source_array, target_array\n",
        "\n",
        "try:\n",
        "    # Load training data\n",
        "    print(\"Loading training data...\")\n",
        "    X_train, y_train = load_listops_data(train_file)\n",
        "\n",
        "    # Load validation data\n",
        "    print(\"Loading validation data...\")\n",
        "    X_val, y_val = load_listops_data(val_file)\n",
        "\n",
        "    # Load test data\n",
        "    print(\"Loading test data...\")\n",
        "    X_test, y_test = load_listops_data(test_file)\n",
        "\n",
        "    # Print dataset statistics\n",
        "    print(\"\\nDataset sizes:\")\n",
        "    print(f\"Training: {len(X_train)} examples\")\n",
        "    print(f\"Validation: {len(X_val)} examples\")\n",
        "    print(f\"Test: {len(X_test)} examples\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error occurred: {type(e).__name__}: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WMm_38sAFAk",
        "outputId": "093cd983-abf4-4ad7-9832-9bb19ed78b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data...\n",
            "Loading validation data...\n",
            "Loading test data...\n",
            "\n",
            "Dataset sizes:\n",
            "Training: 96000 examples\n",
            "Validation: 2000 examples\n",
            "Test: 2000 examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # Separate sequences and targets\n",
        "    sequences = [item['input_ids'] for item in batch]\n",
        "    targets = [item['target'] for item in batch]\n",
        "\n",
        "    # Get lengths of each sequence\n",
        "    lengths = torch.tensor([len(seq) for seq in sequences], dtype=torch.long, device=sequences[0].device)\n",
        "\n",
        "    # Sort sequences by length in descending order for pack_padded_sequence\n",
        "    lengths, sort_idx = lengths.sort(descending=True)\n",
        "    sequences = [sequences[i] for i in sort_idx]\n",
        "    targets = [targets[i] for i in sort_idx]\n",
        "\n",
        "    # Pad sequences\n",
        "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
        "\n",
        "    # Convert targets to tensor\n",
        "    targets = torch.stack(targets)\n",
        "\n",
        "    return {\n",
        "        'input_ids': padded_sequences,\n",
        "        'target': targets,\n",
        "        'lengths': lengths\n",
        "    }\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ListOpsDataset(X_train, y_train)\n",
        "val_dataset = ListOpsDataset(X_val, y_val)\n",
        "test_dataset = ListOpsDataset(X_test, y_test)\n",
        "\n",
        "# Create dataloaders with collate_fn\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "# Verify the data\n",
        "print(\"Dataset sizes:\")\n",
        "print(f\"Train: {len(train_dataset)}\")\n",
        "print(f\"Val: {len(val_dataset)}\")\n",
        "print(f\"Test: {len(test_dataset)}\")\n",
        "\n",
        "# Check first batch\n",
        "batch = next(iter(train_loader))\n",
        "print(\"\\nFirst batch shape:\")\n",
        "print(f\"Input IDs: {batch['input_ids'].shape}\")\n",
        "print(f\"Targets: {batch['target'].shape}\")\n",
        "print(f\"Sequence lengths: {batch['lengths']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6GAqvfwEexi",
        "outputId": "3c265670-a34a-4cdf-e5cb-c913dc5af219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset sizes:\n",
            "Train: 96000\n",
            "Val: 2000\n",
            "Test: 2000\n",
            "\n",
            "First batch shape:\n",
            "Input IDs: torch.Size([32, 1951])\n",
            "Targets: torch.Size([32])\n",
            "Sequence lengths: tensor([1951, 1833, 1744, 1743, 1614, 1472, 1448, 1238, 1229, 1143, 1058,  992,\n",
            "         962,  937,  891,  878,  863,  859,  829,  787,  768,  741,  722,  709,\n",
            "         703,  681,  611,  606,  602,  568,  565,  517])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model choice"
      ],
      "metadata": {
        "id": "m4V1uEkLG_S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def collate_fn(batch):\n",
        "    # Separate sequences and targets\n",
        "    sequences = [item['input_ids'] for item in batch]\n",
        "    targets = [item['target'] for item in batch]\n",
        "\n",
        "    # Get lengths of each sequence\n",
        "    lengths = torch.tensor([len(seq) for seq in sequences], dtype=torch.long, device=sequences[0].device)\n",
        "\n",
        "    # Sort sequences by length in descending order for pack_padded_sequence\n",
        "    lengths, sort_idx = lengths.sort(descending=True)\n",
        "    sequences = [sequences[i] for i in sort_idx]\n",
        "    targets = [targets[i] for i in sort_idx]\n",
        "\n",
        "    # Pad sequences\n",
        "    padded_sequences = pad_sequence(sequences, batch_first=True)\n",
        "\n",
        "    # Convert targets to tensor\n",
        "    targets = torch.stack(targets)\n",
        "\n",
        "    return {\n",
        "        'input_ids': padded_sequences,\n",
        "        'target': targets,\n",
        "        'lengths': lengths\n",
        "    }"
      ],
      "metadata": {
        "id": "bYAQUkw5AFJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, hidden_dim, num_layers, num_classes, max_seq_length=5000, dropout=0.1):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.pos_embedding = nn.Embedding(max_seq_length, embed_dim)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_dim,\n",
        "            dropout=dropout,\n",
        "            activation='relu'\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(embed_dim, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # input_ids: (batch_size, seq_len)\n",
        "        # attention_mask: (batch_size, seq_len)\n",
        "        batch_size, seq_len = input_ids.size()\n",
        "        device = input_ids.device\n",
        "\n",
        "        # Generate position indices and get positional embeddings\n",
        "        positions = torch.arange(0, seq_len, device=device).unsqueeze(0).expand(batch_size, seq_len)\n",
        "        x = self.embedding(input_ids) + self.pos_embedding(positions)\n",
        "\n",
        "        # Prepare input for transformer (seq_len, batch_size, embed_dim)\n",
        "        x = x.transpose(0, 1)\n",
        "\n",
        "        # Create source key padding mask (batch_size, seq_len)\n",
        "        src_key_padding_mask = attention_mask == 0  # True for padding tokens\n",
        "\n",
        "        # Pass through Transformer Encoder\n",
        "        x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        # Convert back to (batch_size, seq_len, embed_dim)\n",
        "        x = x.transpose(0, 1)\n",
        "\n",
        "        # Pooling: Mean over the sequence length\n",
        "        x = torch.mean(x, dim=1)  # (batch_size, embed_dim)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Classification head\n",
        "        logits = self.fc_out(x)  # (batch_size, num_classes)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "B412JHkGBvDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    # Separate sequences and targets\n",
        "    sequences = [item['input_ids'] for item in batch]\n",
        "    targets = [item['target'] for item in batch]\n",
        "\n",
        "    # Pad sequences\n",
        "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Create attention masks (1 for tokens, 0 for padding)\n",
        "    attention_mask = (padded_sequences != 0).long()\n",
        "\n",
        "    # Convert targets to tensor\n",
        "    targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "    return {\n",
        "        'input_ids': padded_sequences,\n",
        "        'attention_mask': attention_mask,\n",
        "        'target': targets\n",
        "    }\n"
      ],
      "metadata": {
        "id": "lYUPZ0ACBv5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_fn\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=collate_fn\n",
        ")\n"
      ],
      "metadata": {
        "id": "b6PBEaTFBv76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary size from your dataset\n",
        "vocab_size = len(train_dataset.vocab)\n",
        "\n",
        "# Hyperparameters\n",
        "embed_dim = 128\n",
        "num_heads = 4\n",
        "hidden_dim = 256\n",
        "num_layers = 2\n",
        "num_classes = 10  # Since targets are 0-9\n",
        "dropout = 0.1\n",
        "max_seq_length = 5000  # Adjust if your sequences are longer\n",
        "\n",
        "# Initialize the model\n",
        "model = TransformerClassifier(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=embed_dim,\n",
        "    num_heads=num_heads,\n",
        "    hidden_dim=hidden_dim,\n",
        "    num_layers=num_layers,\n",
        "    num_classes=num_classes,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dropout=dropout\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrkD0rNhBv_f",
        "outputId": "26ccd194-6a3f-4eba-adf5-d034af4ed477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnI86peAEk9P",
        "outputId": "55a2225f-3485-4b11-86c0-ee8af7ad21b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerClassifier(\n",
              "  (embedding): Embedding(18, 128, padding_idx=0)\n",
              "  (pos_embedding): Embedding(5000, 128)\n",
              "  (transformer_encoder): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-1): 2 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
              "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (fc_out): Linear(in_features=128, out_features=10, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * input_ids.size(0)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = correct / total * 100\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            total_loss += loss.item() * input_ids.size(0)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = correct / total * 100\n",
        "    return avg_loss, accuracy\n"
      ],
      "metadata": {
        "id": "nMV0ubBkEk_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5  # Adjust as needed\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%')\n",
        "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\\n')\n"
      ],
      "metadata": {
        "id": "mMIZF4FDElCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n"
      ],
      "metadata": {
        "id": "THp2hSveElF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pbx9hRFwFO5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C1CX-SnQFxH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iMDU-6EQFxKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "LWNR54NkFxMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWCuMb7LFxPS",
        "outputId": "1d73d383-cb3e-4559-9c23-d4fe64851a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Your ListOpsDataset class and other functions (tokenize, etc.) are assumed to be defined already\n",
        "\n",
        "# Define the TransformerClassifier model\n",
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_heads, hidden_dim, num_layers, num_classes, max_seq_length=5000, dropout=0.1):\n",
        "        super(TransformerClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.pos_embedding = nn.Embedding(max_seq_length, embed_dim)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            dim_feedforward=hidden_dim,\n",
        "            dropout=dropout,\n",
        "            activation='relu'\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(embed_dim, num_classes)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        batch_size, seq_len = input_ids.size()\n",
        "        device = input_ids.device\n",
        "\n",
        "        positions = torch.arange(0, seq_len, device=device).unsqueeze(0).expand(batch_size, seq_len)\n",
        "        x = self.embedding(input_ids) + self.pos_embedding(positions)\n",
        "\n",
        "        x = x.transpose(0, 1)  # Transformer expects (seq_len, batch_size, embed_dim)\n",
        "\n",
        "        src_key_padding_mask = attention_mask == 0  # True for padding tokens\n",
        "        x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "        x = x.transpose(0, 1)  # Back to (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        x = torch.mean(x, dim=1)  # Pooling\n",
        "        x = self.dropout(x)\n",
        "        logits = self.fc_out(x)\n",
        "        return logits\n",
        "\n",
        "# Update collate_fn\n",
        "def collate_fn(batch):\n",
        "    sequences = [item['input_ids'] for item in batch]\n",
        "    targets = [item['target'] for item in batch]\n",
        "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
        "    attention_mask = (padded_sequences != 0).long()\n",
        "    targets = torch.tensor(targets, dtype=torch.long)\n",
        "    return {\n",
        "        'input_ids': padded_sequences,\n",
        "        'attention_mask': attention_mask,\n",
        "        'target': targets\n",
        "    }\n",
        "\n",
        "# Create datasets and data loaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_fn)\n",
        "\n",
        "# Initialize the model\n",
        "vocab_size = len(train_dataset.vocab)\n",
        "embed_dim = 128\n",
        "num_heads = 4\n",
        "hidden_dim = 256\n",
        "num_layers = 2\n",
        "num_classes = 10\n",
        "dropout = 0.1\n",
        "max_seq_length = 5000  # Adjust if necessary\n",
        "\n",
        "model = TransformerClassifier(\n",
        "    vocab_size=vocab_size,\n",
        "    embed_dim=embed_dim,\n",
        "    num_heads=num_heads,\n",
        "    hidden_dim=hidden_dim,\n",
        "    num_layers=num_layers,\n",
        "    num_classes=num_classes,\n",
        "    max_seq_length=max_seq_length,\n",
        "    dropout=dropout\n",
        ")\n",
        "\n",
        "# Set up training components\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Training and evaluation loops\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        targets = batch['target'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * input_ids.size(0)\n",
        "        _, predicted = torch.max(outputs, dim=1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = correct / total * 100\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            targets = batch['target'].to(device)\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item() * input_ids.size(0)\n",
        "            _, predicted = torch.max(outputs, dim=1)\n",
        "            total += targets.size(0)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "    avg_loss = total_loss / total\n",
        "    accuracy = correct / total * 100\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.2f}%')\n",
        "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.2f}%\\n')\n",
        "\n",
        "# Testing the model\n",
        "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
        "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k3_U4GRfFxSs",
        "outputId": "83c95908-5d61-445b-f915-75d38109e303"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "Train Loss: 1.7485, Train Accuracy: 35.20%\n",
            "Validation Loss: 1.6919, Validation Accuracy: 35.85%\n",
            "\n",
            "Epoch 2/5\n",
            "Train Loss: 1.6582, Train Accuracy: 36.71%\n",
            "Validation Loss: 1.6630, Validation Accuracy: 35.60%\n",
            "\n",
            "Epoch 3/5\n",
            "Train Loss: 1.6304, Train Accuracy: 37.07%\n",
            "Validation Loss: 1.6373, Validation Accuracy: 35.80%\n",
            "\n",
            "Epoch 4/5\n",
            "Train Loss: 1.6132, Train Accuracy: 37.57%\n",
            "Validation Loss: 1.6245, Validation Accuracy: 37.00%\n",
            "\n",
            "Epoch 5/5\n",
            "Train Loss: 1.6052, Train Accuracy: 37.75%\n",
            "Validation Loss: 1.6432, Validation Accuracy: 38.10%\n",
            "\n",
            "Test Loss: 1.6071, Test Accuracy: 38.65%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'transformer_classifier.pth')\n"
      ],
      "metadata": {
        "id": "LNKZ6w68FO8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}